{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - NLP and Deep Learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11: Generative LM's and RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will complement a generative language model with Retrieval Augmented Generation (RAG). More precisely, we will improve the language models ability to answer Star Wars trivia questions. \n",
    "\n",
    "For these assignment we will assume you have the Transformers and NLTK package (with 'punkt') installed, you can do this by running:\n",
    "```\n",
    "pip3 install transformers\n",
    "pip3 install nltk\n",
    "\n",
    "python3\n",
    "nltk.download('punkt')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. QA with Flan-T5\n",
    "\n",
    "We have provided:\n",
    "\n",
    "- gold data: The questions and gold answers can be found in `questions.txt` and `answers.txt`. The data is not tokenized\n",
    "- raw data: a (subset of) a scrape of wookipedia in `starwarsfandomcom-20200223.txt.filtered.tokked.gz`\n",
    "- list of English words from Aspell dictionary in `en-aspell-dict.txt`\n",
    "- code: code that loads the questions, supplements them with a prompt, queries the language model, and evaluates performance.\n",
    "\n",
    "The code uses flan-t5-base by default, which can be ran on a 8gb of memory (GPU/RAM), you can also experiment with other models. (use google/flan-t5-small if you have less memory available).\n",
    "\n",
    "It should be noted that evaluation is done with a non-standard metric (which mostly follows Rob's intuition of what should be counted correct):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(gold, pred):\n",
    "    \"\"\"\n",
    "    An answer is considered correct if at least half of the gold\n",
    "    tokens are in the prediction. Note that this is a shortcut, \n",
    "    and will favor long answers.\n",
    "    \"\"\"\n",
    "    gold = set(gold.strip().lower().replace('.', '').split(' '))\n",
    "    pred = set(pred.strip().lower().replace('.', '').split(' '))\n",
    "    return len(gold.intersection(pred)) >= len(gold)/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for querying the model and evaluating its performance is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#lms = ['google/flan-t5-base', 'google/flan-t5-large', 'google/flan-t5-xl', 'google/flan-t5-xxl', 'mistralai/Mistral-7B-v0.1', 'mistralai/Mistral-7B-Instruct-v0.2', 'meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-7b-chat-hf' , 'google/gemma-2b', 'google/gemma-2b-it', 'EleutherAI/pythia-6.9b', 'tiiuae/falcon-7b', 'falcon-7b-instruct', 'microsoft/phi-2']\n",
    "lms = ['google/flan-t5-base']\n",
    "\n",
    "questions = open('questions.txt').readlines()\n",
    "answers = open('answers.txt').readlines()\n",
    "#questions = ['What is the capital of Denmark ?']\n",
    "#answers = ['Copenhagen']\n",
    "\n",
    "# we will consider the prompt to be given for this project\n",
    "prefix = 'Q: '\n",
    "suffix = 'A: '\n",
    "\n",
    "\n",
    "def eval_lm(lm, contexts = []):\n",
    "    # for some of the language models, a token from huggingface needs to be used. \n",
    "    # This can be saved in a file called token. If a t5-based model is used this \n",
    "    # is not necessary.\n",
    "    if 't5' in lm:\n",
    "        lang_model = T5ForConditionalGeneration.from_pretrained(lm)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(lm, legacy=False)\n",
    "    else:\n",
    "        lang_model = AutoModelForCausalLM.from_pretrained(lm, token=open('token').readline().strip())\n",
    "        tokenizer = AutoTokenizer.from_pretrained(lm, legacy=False, token=open('token').readline().strip())\n",
    "\n",
    "    lang_model.to(DEVICE)\n",
    "\n",
    "    if contexts == []:\n",
    "        contexts = [''] * len(questions)\n",
    "    correct = 0\n",
    "    for question, answer, context in zip(questions, answers, contexts):\n",
    "        # Prepare input\n",
    "        question = context + prefix + ' ' + question.strip() + ' ' + suffix\n",
    "        subword_ids = tokenizer(question.strip(), return_tensors='pt')['input_ids']\n",
    "        subword_ids = subword_ids.to(DEVICE)\n",
    "        \n",
    "        # Generate output from model\n",
    "        generated_ids = lang_model.generate(subword_ids, max_new_tokens=20)\n",
    "        subwords_out = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        #print()\n",
    "        #print(question)\n",
    "        #print(' '.join(subwords_out))\n",
    "        \n",
    "        # Evaluate\n",
    "        correct += int(eval_metric(answer, ' '.join(subwords_out)))\n",
    "\n",
    "    print(str(correct) + ' out of ' + str(len(answers)) + ' correct', flush=True)\n",
    "    \n",
    "for lm in lms:\n",
    "    eval_lm(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG (Retrieval Augmented generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Retrieval Augmented Generation (RAG) to improve the model with relevant information and hopefully increase performance. We are going to do this based on the  `starwarsfandomcom-20200223.txt.filtered.tokked.gz` file, and provide a ranking of sentence importances, from which we will use the 5 highest ranked sentences as additional context.\n",
    "\n",
    "You are encouraged to evaluate a variety of ranking approaches, in which you can make use of any technologies described in the course (TF-IDF, n-grams), and also external resources (POS tagger, NER tagger, lemmatizer, sentence embeddings, etc.). Of course heuristics based approaches can also be included, like the example below. \n",
    "\n",
    "Below we provide a simple example that extracts all words that are not found in an English word list, and then finds all sentences in the data that contain all these words. You can use this as a starting point (e.g. find more, filter better based on verbs/nouns, improve ranking), but you can also implement your own strategies from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data = [str(x).strip() for x in gzip.open('starwarsfandomcom-20200223.txt.filtered.tokked.gz').readlines()]\n",
    "\n",
    "\n",
    "def eval_plus_contexts(lm, data, context_indices):\n",
    "    contexts = []\n",
    "    # first collect the context\n",
    "    for question_context in context_indices:\n",
    "        context = ''\n",
    "        for sent_id in question_context[:5]:\n",
    "            context += data[sent_id] + '\\n'\n",
    "        contexts.append(context)\n",
    "    eval_lm(lm, contexts)\n",
    "\n",
    "def hasAlpha(word):\n",
    "    for char in word:\n",
    "        if char.isalpha():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# simple approach that extracts all words not in a dictionary, and then returns the \n",
    "# indices of the sentences containing all these \"raw\" words.\n",
    "en_vocab = set([x.strip() for x in open('en-aspell-dict.txt').readlines()])\n",
    "en_vocab.add(\"'s\")\n",
    "en_vocab.add(\"n't\")\n",
    "en_vocab.add(\"'re\")\n",
    "context_ids = []\n",
    "\n",
    "for question in questions:\n",
    "    # collect all rare words\n",
    "    rares = []\n",
    "    for word in word_tokenize(question):\n",
    "        if word.lower() not in en_vocab and hasAlpha(word):\n",
    "            rares.append(word)\n",
    "            \n",
    "    # Find indices of sentences that contain all rare words\n",
    "    found_all_indices = []\n",
    "    if len(rares) > 0:\n",
    "        for lineIdx, line in enumerate(data):\n",
    "            allIn = True\n",
    "            for rare in rares:\n",
    "                if rare not in line:\n",
    "                    allIn = False\n",
    "                    break\n",
    "            if allIn:\n",
    "                found_all_indices.append(lineIdx)\n",
    "    context_ids.append(found_all_indices)\n",
    "    \n",
    "# Prepare output file for online submission\n",
    "outFile = open('robv-rare.tsv', 'w')\n",
    "for line in context_ids:\n",
    "    outFile.write('\\t'.join([str(indice) for indice in line]) + '\\n')\n",
    "outFile.close()\n",
    "\n",
    "eval_plus_contexts(lms[0], data, context_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Participate\n",
    "\n",
    "We are also making an ensemble of all our approaches during the lab hours. The way this works is that you upload your top-N rankings for the sentences to the onedrive link that was sent to your ITU e-mail (https://ituniversity-my.sharepoint.com/personal/alai_itu_dk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Falai%5Fitu%5Fdk%2FDocuments%2FWeek6&ga=1). You can use your ITU username or another anonymous name followed by a dash followed by the name of the approach, e.g. robv-tfidf robv-bert robv-rarewords etc. THe format is that we have one line for each sentence, and within one line the indices of the relevant sentences (start counting with 0) separated by a tab. In the code snippet above the data is written in the right format (to `robv-rare.tsv`). \n",
    "\n",
    "We will then evaluate all the individual submissions, and take the average of the 5 best rankings as an ensemble model. Note that you can upload multiple rankings, just make sure that each upload has a unique name. If your file does not show up on the leaderboard (http://itu.dk/~robv/alai/website.html) after 5 minutes the format of the file is incorrect, please compare the format to `robv-rare.tsv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
